{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import time\n",
    "import random\n",
    "import math\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load positives from file\n",
    "with open(\"datasets/url_positives.txt\", \"r\") as f:\n",
    "    positives = list(set(f.read().splitlines()))\n",
    "\n",
    "# Load Majestic negatives\n",
    "df = pd.read_csv(\"datasets/majestic_million.csv\")\n",
    "negatives = [domain for domain in df['Domain'][:40000]]\n",
    "\n",
    "# Remove overlaps\n",
    "negatives = list(set(negatives) - set(positives))\n",
    "\n",
    "# Save negatives\n",
    "with open(\"datasets/url_negatives.txt\", \"w\") as f:\n",
    "    for url in negatives:\n",
    "        f.write(url + \"\\n\")\n",
    "\n",
    "# Create queries: 10k positives + 10k negatives\n",
    "query_positives = random.sample(positives, 10000)\n",
    "query_negatives = random.sample(negatives, 10000)\n",
    "queries = query_positives + query_negatives\n",
    "random.shuffle(queries)\n",
    "\n",
    "with open(\"datasets/url_queries.txt\", \"w\") as f:\n",
    "    for url in queries:\n",
    "        f.write(url + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class StandardBloomFilter:\n",
    "    def __init__(self, n, fp_rate):\n",
    "        self.size = self._get_size(n, fp_rate)\n",
    "        self.hash_count = self._get_hash_count(self.size, n)\n",
    "        self.bit_array = [0] * self.size\n",
    "\n",
    "    def _hashes(self, item):\n",
    "        return [hashlib.sha256(f\"{item}{i}\".encode()).hexdigest() for i in range(self.hash_count)]\n",
    "\n",
    "    def _get_size(self, n, p):\n",
    "        m = -(n * math.log(p)) / (math.log(2)**2)\n",
    "        return int(m)\n",
    "\n",
    "    def _get_hash_count(self, m, n):\n",
    "        return int((m / n) * math.log(2))\n",
    "\n",
    "    def add(self, item):\n",
    "        for i in range(self.hash_count):\n",
    "            idx = int(hashlib.md5(f\"{item}{i}\".encode()).hexdigest(), 16) % self.size\n",
    "            self.bit_array[idx] = 1\n",
    "\n",
    "    def query(self, item):\n",
    "        for i in range(self.hash_count):\n",
    "            idx = int(hashlib.md5(f\"{item}{i}\".encode()).hexdigest(), 16) % self.size\n",
    "            if self.bit_array[idx] == 0:\n",
    "                return False\n",
    "        return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CountingBloomFilter:\n",
    "    def __init__(self, n, fp_rate):\n",
    "        self.size = self._get_size(n, fp_rate)\n",
    "        self.hash_count = self._get_hash_count(self.size, n)\n",
    "        self.count_array = [0] * self.size\n",
    "\n",
    "    def _get_size(self, n, p):\n",
    "        return int(-(n * math.log(p)) / (math.log(2)**2))\n",
    "\n",
    "    def _get_hash_count(self, m, n):\n",
    "        return int((m / n) * math.log(2))\n",
    "\n",
    "    def add(self, item):\n",
    "        for i in range(self.hash_count):\n",
    "            idx = int(hashlib.md5(f\"{item}{i}\".encode()).hexdigest(), 16) % self.size\n",
    "            self.count_array[idx] += 1\n",
    "\n",
    "    def remove(self, item):\n",
    "        for i in range(self.hash_count):\n",
    "            idx = int(hashlib.md5(f\"{item}{i}\".encode()).hexdigest(), 16) % self.size\n",
    "            self.count_array[idx] = max(0, self.count_array[idx] - 1)\n",
    "\n",
    "    def query(self, item):\n",
    "        for i in range(self.hash_count):\n",
    "            idx = int(hashlib.md5(f\"{item}{i}\".encode()).hexdigest(), 16) % self.size\n",
    "            if self.count_array[idx] == 0:\n",
    "                return False\n",
    "        return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class NeuralNetworkBloomFilter:\n",
    "    def __init__(self):\n",
    "        self.model = MLPClassifier(hidden_layer_sizes=(10,), max_iter=200)\n",
    "        self.set_members = set()\n",
    "\n",
    "    def _featurize(self, url):\n",
    "        return np.array([ord(c) for c in url[:50]] + [0] * (50 - len(url))).reshape(1, -1)\n",
    "\n",
    "    def train(self, positives, negatives):\n",
    "        X = [self._featurize(x).flatten() for x in positives + negatives]\n",
    "        y = [1]*len(positives) + [0]*len(negatives)\n",
    "        self.model.fit(X, y)\n",
    "        self.set_members = set(positives)\n",
    "\n",
    "    def add(self, item): pass  # Not used\n",
    "\n",
    "    def query(self, item):\n",
    "        x = self._featurize(item)\n",
    "        pred = self.model.predict(x)[0]\n",
    "        if pred == 1:\n",
    "            return True\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(bloom_filter, positives, negatives):\n",
    "    # Insert positives\n",
    "    for url in positives:\n",
    "        bloom_filter.add(url)\n",
    "\n",
    "    # Evaluate FPR and query time\n",
    "    start = time.time()\n",
    "    false_positives = 0\n",
    "    for url in negatives:\n",
    "        if bloom_filter.query(url):\n",
    "            false_positives += 1\n",
    "    elapsed = time.time() - start\n",
    "    fpr = false_positives / len(negatives)\n",
    "    avg_query_time = elapsed / len(negatives)\n",
    "    return fpr, avg_query_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "with open(\"datasets/url_positives.txt\") as f:\n",
    "    positives = f.read().splitlines()\n",
    "\n",
    "with open(\"datasets/url_negatives.txt\") as f:\n",
    "    negatives = f.read().splitlines()\n",
    "\n",
    "# Evaluate Standard Bloom Filter\n",
    "sbf = StandardBloomFilter(n=len(positives), fp_rate=0.01)\n",
    "fpr, time_sbf = evaluate(sbf, positives, negatives)\n",
    "print(\"Standard Bloom Filter: FPR =\", fpr, \"Avg Query Time =\", time_sbf)\n",
    "\n",
    "# Evaluate Counting Bloom Filter\n",
    "cbf = CountingBloomFilter(n=len(positives), fp_rate=0.01)\n",
    "fpr, time_cbf = evaluate(cbf, positives, negatives)\n",
    "print(\"Counting Bloom Filter: FPR =\", fpr, \"Avg Query Time =\", time_cbf)\n",
    "\n",
    "# Evaluate Neural Network Bloom Filter\n",
    "nn_bf = NeuralNetworkBloomFilter()\n",
    "nn_bf.train(positives, negatives)\n",
    "fpr, time_nn = evaluate(nn_bf, positives, negatives)\n",
    "print(\"Neural Network BF: FPR =\", fpr, \"Avg Query Time =\", time_nn)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
