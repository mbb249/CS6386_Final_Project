{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import time\n",
    "import random\n",
    "import math\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import sys\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StandardBloomFilter:\n",
    "    def __init__(self, n, fp_rate):\n",
    "        self.size = self._get_size(n, fp_rate)\n",
    "        self.hash_count = self._get_hash_count(self.size, n)\n",
    "        self.bit_array = [0] * self.size\n",
    "\n",
    "    def _hashes(self, item):\n",
    "        return [hashlib.sha256(f\"{item}{i}\".encode()).hexdigest() for i in range(self.hash_count)]\n",
    "\n",
    "    def _get_size(self, n, p):\n",
    "        m = -(n * math.log(p)) / (math.log(2)**2)\n",
    "        return int(m)\n",
    "\n",
    "    def _get_hash_count(self, m, n):\n",
    "        return int((m / n) * math.log(2))\n",
    "\n",
    "    def add(self, item):\n",
    "        for i in range(self.hash_count):\n",
    "            idx = int(hashlib.md5(f\"{item}{i}\".encode()).hexdigest(), 16) % self.size\n",
    "            self.bit_array[idx] = 1\n",
    "\n",
    "    def query(self, item):\n",
    "        for i in range(self.hash_count):\n",
    "            idx = int(hashlib.md5(f\"{item}{i}\".encode()).hexdigest(), 16) % self.size\n",
    "            if self.bit_array[idx] == 0:\n",
    "                return False\n",
    "        return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CountingBloomFilter:\n",
    "    def __init__(self, n, fp_rate):\n",
    "        self.size = self._get_size(n, fp_rate)\n",
    "        self.hash_count = self._get_hash_count(self.size, n)\n",
    "        self.count_array = [0] * self.size\n",
    "\n",
    "    def _get_size(self, n, p):\n",
    "        return int(-(n * math.log(p)) / (math.log(2)**2))\n",
    "\n",
    "    def _get_hash_count(self, m, n):\n",
    "        return int((m / n) * math.log(2))\n",
    "\n",
    "    def add(self, item):\n",
    "        for i in range(self.hash_count):\n",
    "            idx = int(hashlib.md5(f\"{item}{i}\".encode()).hexdigest(), 16) % self.size\n",
    "            self.count_array[idx] += 1\n",
    "\n",
    "    def remove(self, item):\n",
    "        for i in range(self.hash_count):\n",
    "            idx = int(hashlib.md5(f\"{item}{i}\".encode()).hexdigest(), 16) % self.size\n",
    "            self.count_array[idx] = max(0, self.count_array[idx] - 1)\n",
    "\n",
    "    def query(self, item):\n",
    "        for i in range(self.hash_count):\n",
    "            idx = int(hashlib.md5(f\"{item}{i}\".encode()).hexdigest(), 16) % self.size\n",
    "            if self.count_array[idx] == 0:\n",
    "                return False\n",
    "        return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class NeuralNetworkBloomFilter:\n",
    "    def __init__(self):\n",
    "        self.model = MLPClassifier(hidden_layer_sizes=(10,), max_iter=200)\n",
    "        self.set_members = set()\n",
    "\n",
    "    def _featurize(self, url):\n",
    "        return np.array([ord(c) for c in url[:50]] + [0] * (50 - len(url))).reshape(1, -1)\n",
    "\n",
    "    def train(self, positives, negatives):\n",
    "        X = [self._featurize(x).flatten() for x in positives + negatives]\n",
    "        y = [1]*len(positives) + [0]*len(negatives)\n",
    "        self.model.fit(X, y)\n",
    "        self.set_members = set(positives)\n",
    "\n",
    "    def add(self, item): pass  # Not used\n",
    "\n",
    "    def query(self, item):\n",
    "        x = self._featurize(item)\n",
    "        pred = self.model.predict(x)[0]\n",
    "        if pred == 1:\n",
    "            return True\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForestBloomFilter:\n",
    "    def __init__(self, **rf_kwargs):\n",
    "        # you can pass n_estimators, max_depth, etc.\n",
    "        self.model = RandomForestClassifier(**rf_kwargs)\n",
    "        self.set_members = set()\n",
    "\n",
    "    def _featurize(self, x):\n",
    "        arr = [ord(c) for c in x[:50]] + [0]*(50 - len(x))\n",
    "        return np.array(arr).reshape(1, -1)\n",
    "\n",
    "    def train(self, positives, negatives):\n",
    "        X = np.vstack([self._featurize(u) for u in positives + negatives])\n",
    "        y = np.array([1]*len(positives) + [0]*len(negatives))\n",
    "        self.model.fit(X, y)\n",
    "        self.set_members = set(positives)\n",
    "\n",
    "    def add(self, item):\n",
    "        pass  # not used\n",
    "\n",
    "    def query(self, item):\n",
    "        if item in self.set_members:\n",
    "            return True\n",
    "        x = self._featurize(item)\n",
    "        return bool(self.model.predict(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionBloomFilter:\n",
    "    def __init__(self, **lr_kwargs):\n",
    "        self.model = LogisticRegression(**lr_kwargs)\n",
    "        self.set_members = set()\n",
    "\n",
    "    def _featurize(self, x):\n",
    "        arr = [ord(c) for c in x[:50]] + [0]*(50 - len(x))\n",
    "        return np.array(arr).reshape(1, -1)\n",
    "\n",
    "    def train(self, positives, negatives):\n",
    "        X = np.vstack([self._featurize(u) for u in positives + negatives])\n",
    "        y = np.array([1]*len(positives) + [0]*len(negatives))\n",
    "        self.model.fit(X, y)\n",
    "        self.set_members = set(positives)\n",
    "\n",
    "    def add(self, item):\n",
    "        pass\n",
    "\n",
    "    def query(self, item):\n",
    "        if item in self.set_members:\n",
    "            return True\n",
    "        x = self._featurize(item)\n",
    "        return bool(self.model.predict(x)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SandwichBloomFilter:\n",
    "    def __init__(self, ml_filter, positives, negatives, fp_rate_small=0.20):\n",
    "        \"\"\"\n",
    "        ml_filter: any object with .train(positives, negatives) and .query(item)\n",
    "        \"\"\"\n",
    "        self.ml = ml_filter\n",
    "        self.ml.train(positives, negatives)\n",
    "\n",
    "        # small classical BF to catch anything the ML lets through\n",
    "        self.small = StandardBloomFilter(len(positives), fp_rate_small)\n",
    "        for u in positives:\n",
    "            self.small.add(u)\n",
    "\n",
    "    def add(self, item):\n",
    "        pass\n",
    "\n",
    "    def query(self, item):\n",
    "        if not self.ml.query(item):\n",
    "            return False\n",
    "        return self.small.query(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_memory_usage(bf):\n",
    "    \"\"\"Estimate memory used by each filter.\"\"\"\n",
    "    size = sys.getsizeof(bf)\n",
    "\n",
    "    # classical bit/count arrays\n",
    "    if hasattr(bf, 'bit_array'):\n",
    "        size += sys.getsizeof(bf.bit_array)\n",
    "    if hasattr(bf, 'count_array'):\n",
    "        size += sys.getsizeof(bf.count_array)\n",
    "\n",
    "    # Sandwich: just sum its two parts\n",
    "    if hasattr(bf, 'small') and hasattr(bf, 'ml'):\n",
    "        return get_memory_usage(bf.ml) + get_memory_usage(bf.small)\n",
    "\n",
    "    # any ML‚Äêbased filter with a .model\n",
    "    if hasattr(bf, 'model'):\n",
    "        mdl = bf.model\n",
    "\n",
    "        # neural networks & logistic regression have coefs_ / intercepts_\n",
    "        if hasattr(mdl, 'coefs_'):\n",
    "            for coef in mdl.coefs_:\n",
    "                size += coef.nbytes\n",
    "            for intercept in mdl.intercepts_:\n",
    "                size += intercept.nbytes\n",
    "\n",
    "        # random forests have many tree estimators\n",
    "        if hasattr(mdl, 'estimators_'):\n",
    "            for tree_est in mdl.estimators_:\n",
    "                tree = tree_est.tree_\n",
    "                # pick the big arrays inside each tree\n",
    "                for arr_name in ('threshold', 'feature', 'children_left',\n",
    "                                 'children_right', 'value'):\n",
    "                    arr = getattr(tree, arr_name, None)\n",
    "                    if isinstance(arr, np.ndarray):\n",
    "                        size += arr.nbytes\n",
    "\n",
    "    return size\n",
    "\n",
    "\n",
    "my_set = set()\n",
    "\n",
    "for i in range(40000):\n",
    "    my_set.add(i)\n",
    "    \n",
    "print(get_memory_usage(my_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(bf, positives, negatives):\n",
    "    \"\"\"Run insertions and then measure FP, FN (for NN), timing, throughput, memory.\"\"\"\n",
    "    # ‚Äî insert positives ‚Äî\n",
    "    for url in positives:\n",
    "        bf.add(url)\n",
    "\n",
    "    # ‚Äî measure false positives ‚Äî\n",
    "    start = time.time()\n",
    "    false_positives = sum(1 for url in negatives if bf.query(url) and url not in positives)\n",
    "    elapsed = time.time() - start\n",
    "\n",
    "    # ‚Äî measure false negatives (only makes sense for NN-based filters) ‚Äî\n",
    "    false_negatives = 0\n",
    "    if isinstance(bf, NeuralNetworkBloomFilter) or isinstance(bf, RandomForestBloomFilter) or isinstance(bf, LogisticRegressionBloomFilter) :\n",
    "        for url in positives:\n",
    "            if not bf.query(url):\n",
    "                false_negatives += 1\n",
    "    fnr = false_negatives / len(positives) if positives else 0.0\n",
    "\n",
    "    # ‚Äî compute metrics ‚Äî\n",
    "    fpr = false_positives / len(negatives)\n",
    "    avg_query_time = elapsed / len(negatives)\n",
    "    throughput = len(negatives) / elapsed if elapsed > 0 else float('inf')\n",
    "    mem_bytes = get_memory_usage(bf)\n",
    "\n",
    "    # ‚Äî print a summary ‚Äî\n",
    "    print(f\"\\n=== {bf.__class__.__name__} ===\")\n",
    "    print(f\"Memory Usage:             {mem_bytes:,} bytes\")\n",
    "    print(f\"False‚ÄêPositive Rate:      {fpr:.4%}\")\n",
    "    if isinstance(bf, NeuralNetworkBloomFilter) or isinstance(bf, RandomForestBloomFilter) or isinstance(bf, LogisticRegressionBloomFilter) :\n",
    "        print(f\"False‚ÄêNegative Rate:      {fnr:.4%}\")\n",
    "    print(f\"Avg Query Time:           {avg_query_time:.6f} s\")\n",
    "    print(f\"Throughput:               {throughput:,.0f} queries/s\")\n",
    "\n",
    "    return {\n",
    "        'fpr': fpr,\n",
    "        'fnr': fnr if isinstance(bf, NeuralNetworkBloomFilter) or isinstance(bf, RandomForestBloomFilter) or isinstance(bf, LogisticRegressionBloomFilter) else None,\n",
    "        'avg_time': avg_query_time,\n",
    "        'throughput': throughput,\n",
    "        'memory_bytes': mem_bytes\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåê URL Dataset Bloom Filter Evaluation\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/milesbramwit/cs6386/finalProject/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== StandardBloomFilter ===\n",
      "Memory Usage:             1,708,776 bytes\n",
      "False‚ÄêPositive Rate:      10.1150%\n",
      "Avg Query Time:           0.000044 s\n",
      "Throughput:               22,638 queries/s\n",
      "\n",
      "=== CountingBloomFilter ===\n",
      "Memory Usage:             1,708,776 bytes\n",
      "False‚ÄêPositive Rate:      10.1150%\n",
      "Avg Query Time:           0.000044 s\n",
      "Throughput:               22,645 queries/s\n",
      "\n",
      "=== NeuralNetworkBloomFilter ===\n",
      "Memory Usage:             4,224 bytes\n",
      "False‚ÄêPositive Rate:      31.2600%\n",
      "False‚ÄêNegative Rate:      20.5897%\n",
      "Avg Query Time:           0.000217 s\n",
      "Throughput:               4,612 queries/s\n",
      "\n",
      "=== RandomForestBloomFilter ===\n",
      "Memory Usage:             133,940,792 bytes\n",
      "False‚ÄêPositive Rate:      0.0000%\n",
      "False‚ÄêNegative Rate:      0.0000%\n",
      "Avg Query Time:           0.004179 s\n",
      "Throughput:               239 queries/s\n",
      "\n",
      "=== LogisticRegressionBloomFilter ===\n",
      "Memory Usage:             56 bytes\n",
      "False‚ÄêPositive Rate:      30.6225%\n",
      "False‚ÄêNegative Rate:      0.0000%\n",
      "Avg Query Time:           0.000232 s\n",
      "Throughput:               4,311 queries/s\n",
      "\n",
      "=== SandwichBloomFilter ===\n",
      "Memory Usage:             1,198,640 bytes\n",
      "False‚ÄêPositive Rate:      6.3000%\n",
      "Avg Query Time:           0.000113 s\n",
      "Throughput:               8,826 queries/s\n",
      "\n",
      "=== SandwichBloomFilter ===\n",
      "Memory Usage:             135,135,208 bytes\n",
      "False‚ÄêPositive Rate:      0.0000%\n",
      "Avg Query Time:           0.004048 s\n",
      "Throughput:               247 queries/s\n",
      "\n",
      "=== SandwichBloomFilter ===\n",
      "Memory Usage:             1,194,472 bytes\n",
      "False‚ÄêPositive Rate:      6.1825%\n",
      "Avg Query Time:           0.000104 s\n",
      "Throughput:               9,575 queries/s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filter</th>\n",
       "      <th>Mem (bytes)</th>\n",
       "      <th>FP Rate</th>\n",
       "      <th>FN Rate</th>\n",
       "      <th>Avg Time (s)</th>\n",
       "      <th>Throughput (q/s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Standard</td>\n",
       "      <td>1708776</td>\n",
       "      <td>0.101150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>22637.672504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Counting</td>\n",
       "      <td>1708776</td>\n",
       "      <td>0.101150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>22645.021021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NeuralNet</td>\n",
       "      <td>4224</td>\n",
       "      <td>0.312600</td>\n",
       "      <td>0.205897</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>4611.776539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>133940792</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004179</td>\n",
       "      <td>239.268726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegr</td>\n",
       "      <td>56</td>\n",
       "      <td>0.306225</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000232</td>\n",
       "      <td>4311.381837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sandwich-NeuralNet</td>\n",
       "      <td>1198640</td>\n",
       "      <td>0.063000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>8825.994732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sandwich-RandomForest</td>\n",
       "      <td>135135208</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004048</td>\n",
       "      <td>247.011764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sandwich-LogisticRegr</td>\n",
       "      <td>1194472</td>\n",
       "      <td>0.061825</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>9574.823282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Filter  Mem (bytes)   FP Rate   FN Rate  Avg Time (s)  \\\n",
       "0               Standard      1708776  0.101150       NaN      0.000044   \n",
       "1               Counting      1708776  0.101150       NaN      0.000044   \n",
       "2              NeuralNet         4224  0.312600  0.205897      0.000217   \n",
       "3           RandomForest    133940792  0.000000  0.000000      0.004179   \n",
       "4           LogisticRegr           56  0.306225  0.000000      0.000232   \n",
       "5     Sandwich-NeuralNet      1198640  0.063000       NaN      0.000113   \n",
       "6  Sandwich-RandomForest    135135208  0.000000       NaN      0.004048   \n",
       "7  Sandwich-LogisticRegr      1194472  0.061825       NaN      0.000104   \n",
       "\n",
       "   Throughput (q/s)  \n",
       "0      22637.672504  \n",
       "1      22645.021021  \n",
       "2       4611.776539  \n",
       "3        239.268726  \n",
       "4       4311.381837  \n",
       "5       8825.994732  \n",
       "6        247.011764  \n",
       "7       9574.823282  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# üåê URL Dataset\n",
    "print(\"\\U0001f310 URL Dataset Bloom Filter Evaluation\\n\")\n",
    "with open(\"../datasets/urls/url_positives.txt\") as f:\n",
    "    positives = f.read().splitlines()\n",
    "with open(\"../datasets/urls/url_negatives.txt\") as f:\n",
    "    negatives = f.read().splitlines()\n",
    "\n",
    "ml_filters = [\n",
    "    (\"NeuralNet\",      NeuralNetworkBloomFilter()),\n",
    "    (\"RandomForest\",   RandomForestBloomFilter(n_estimators=100)),\n",
    "    (\"LogisticRegr\",   LogisticRegressionBloomFilter(max_iter=200)),\n",
    "]\n",
    "\n",
    "filters = [\n",
    "    (\"Standard\", StandardBloomFilter(len(positives), 0.10)),\n",
    "    (\"Counting\", CountingBloomFilter(len(positives), 0.10)),\n",
    "]\n",
    "# add the plain ML filters\n",
    "filters += [(name, bf) for name, bf in ml_filters]\n",
    "# add a sandwich for each ML filter\n",
    "filters += [\n",
    "    (f\"Sandwich-{name}\", SandwichBloomFilter(bf, positives, negatives, 0.20))\n",
    "    for name, bf in ml_filters\n",
    "]\n",
    "\n",
    "results_url = []\n",
    "for name, bf in filters:\n",
    "    m = evaluate(bf, positives, negatives)\n",
    "    results_url.append({\n",
    "        \"Filter\":            name,\n",
    "        \"Mem (bytes)\":       m[\"memory_bytes\"],\n",
    "        \"FP Rate\":           m[\"fpr\"],\n",
    "        \"FN Rate\":           m[\"fnr\"],\n",
    "        \"Avg Time (s)\":      m[\"avg_time\"],\n",
    "        \"Throughput (q/s)\":  m[\"throughput\"],\n",
    "    })\n",
    "\n",
    "df_url = pd.DataFrame(results_url)\n",
    "display(df_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîê Password Dataset Bloom Filter Evaluation\n",
      "\n",
      "\n",
      "=== StandardBloomFilter ===\n",
      "Memory Usage:             1,265,728 bytes\n",
      "False‚ÄêPositive Rate:      0.0200%\n",
      "Avg Query Time:           0.000002 s\n",
      "Throughput:               427,210 queries/s\n",
      "\n",
      "=== CountingBloomFilter ===\n",
      "Memory Usage:             1,265,728 bytes\n",
      "False‚ÄêPositive Rate:      0.0200%\n",
      "Avg Query Time:           0.000003 s\n",
      "Throughput:               388,498 queries/s\n",
      "\n",
      "=== NeuralNetworkBloomFilter ===\n",
      "Memory Usage:             4,224 bytes\n",
      "False‚ÄêPositive Rate:      0.2200%\n",
      "False‚ÄêNegative Rate:      0.0600%\n",
      "Avg Query Time:           0.000083 s\n",
      "Throughput:               12,096 queries/s\n",
      "\n",
      "=== RandomForestBloomFilter ===\n",
      "Memory Usage:             245,912 bytes\n",
      "False‚ÄêPositive Rate:      0.0000%\n",
      "False‚ÄêNegative Rate:      0.0000%\n",
      "Avg Query Time:           0.003468 s\n",
      "Throughput:               288 queries/s\n",
      "\n",
      "=== LogisticRegressionBloomFilter ===\n",
      "Memory Usage:             56 bytes\n",
      "False‚ÄêPositive Rate:      1.9200%\n",
      "False‚ÄêNegative Rate:      0.0000%\n",
      "Avg Query Time:           0.000073 s\n",
      "Throughput:               13,692 queries/s\n",
      "\n",
      "=== SandwichBloomFilter ===\n",
      "Memory Usage:             272,320 bytes\n",
      "False‚ÄêPositive Rate:      0.0300%\n",
      "Avg Query Time:           0.000092 s\n",
      "Throughput:               10,833 queries/s\n",
      "\n",
      "=== SandwichBloomFilter ===\n",
      "Memory Usage:             514,008 bytes\n",
      "False‚ÄêPositive Rate:      0.0000%\n",
      "Avg Query Time:           0.003475 s\n",
      "Throughput:               288 queries/s\n",
      "\n",
      "=== SandwichBloomFilter ===\n",
      "Memory Usage:             268,152 bytes\n",
      "False‚ÄêPositive Rate:      0.3600%\n",
      "Avg Query Time:           0.000068 s\n",
      "Throughput:               14,806 queries/s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filter</th>\n",
       "      <th>Mem (bytes)</th>\n",
       "      <th>FP Rate</th>\n",
       "      <th>FN Rate</th>\n",
       "      <th>Avg Time (s)</th>\n",
       "      <th>Throughput (q/s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Standard</td>\n",
       "      <td>1265728</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>427209.892136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Counting</td>\n",
       "      <td>1265728</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>388498.175284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NeuralNet</td>\n",
       "      <td>4224</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>12096.199635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>245912</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.003468</td>\n",
       "      <td>288.330806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegr</td>\n",
       "      <td>56</td>\n",
       "      <td>0.0192</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>13691.712022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sandwich-NeuralNet</td>\n",
       "      <td>272320</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>10833.487877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sandwich-RandomForest</td>\n",
       "      <td>514008</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003475</td>\n",
       "      <td>287.775869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sandwich-LogisticRegr</td>\n",
       "      <td>268152</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>14806.479501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Filter  Mem (bytes)  FP Rate  FN Rate  Avg Time (s)  \\\n",
       "0               Standard      1265728   0.0002      NaN      0.000002   \n",
       "1               Counting      1265728   0.0002      NaN      0.000003   \n",
       "2              NeuralNet         4224   0.0022   0.0006      0.000083   \n",
       "3           RandomForest       245912   0.0000   0.0000      0.003468   \n",
       "4           LogisticRegr           56   0.0192   0.0000      0.000073   \n",
       "5     Sandwich-NeuralNet       272320   0.0003      NaN      0.000092   \n",
       "6  Sandwich-RandomForest       514008   0.0000      NaN      0.003475   \n",
       "7  Sandwich-LogisticRegr       268152   0.0036      NaN      0.000068   \n",
       "\n",
       "   Throughput (q/s)  \n",
       "0     427209.892136  \n",
       "1     388498.175284  \n",
       "2      12096.199635  \n",
       "3        288.330806  \n",
       "4      13691.712022  \n",
       "5      10833.487877  \n",
       "6        287.775869  \n",
       "7      14806.479501  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# üîê Password Dataset\n",
    "print(\"\\U0001f510 Password Dataset Bloom Filter Evaluation\\n\")\n",
    "with open(\"../datasets/passwords/password_positives.txt\") as f:\n",
    "    positives = f.read().splitlines()\n",
    "with open(\"../datasets/passwords/password_negatives.txt\") as f:\n",
    "    negatives = f.read().splitlines()\n",
    "\n",
    "filters_pw = [\n",
    "    (\"Standard\", StandardBloomFilter(len(positives), 0.0005)),\n",
    "    (\"Counting\", CountingBloomFilter(len(positives), 0.0005)),\n",
    "] + [(name, bf) for name, bf in ml_filters] + [\n",
    "    (f\"Sandwich-{name}\", SandwichBloomFilter(bf, positives, negatives, 0.20))\n",
    "    for name, bf in ml_filters\n",
    "]\n",
    "\n",
    "results_pw = []\n",
    "for name, bf in filters_pw:\n",
    "    m = evaluate(bf, positives, negatives)\n",
    "    results_pw.append({\n",
    "        \"Filter\":            name,\n",
    "        \"Mem (bytes)\":       m[\"memory_bytes\"],\n",
    "        \"FP Rate\":           m[\"fpr\"],\n",
    "        \"FN Rate\":           m[\"fnr\"],\n",
    "        \"Avg Time (s)\":      m[\"avg_time\"],\n",
    "        \"Throughput (q/s)\":  m[\"throughput\"],\n",
    "    })\n",
    "\n",
    "df_pw = pd.DataFrame(results_pw)\n",
    "display(df_pw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìè IP Address Dataset Bloom Filter Evaluation\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/milesbramwit/cs6386/finalProject/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/milesbramwit/cs6386/finalProject/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== StandardBloomFilter ===\n",
      "Memory Usage:             3,067,328 bytes\n",
      "False‚ÄêPositive Rate:      0.9625%\n",
      "Avg Query Time:           0.000007 s\n",
      "Throughput:               142,570 queries/s\n",
      "\n",
      "=== CountingBloomFilter ===\n",
      "Memory Usage:             3,067,328 bytes\n",
      "False‚ÄêPositive Rate:      0.9625%\n",
      "Avg Query Time:           0.000007 s\n",
      "Throughput:               143,614 queries/s\n",
      "\n",
      "=== NeuralNetworkBloomFilter ===\n",
      "Memory Usage:             4,224 bytes\n",
      "False‚ÄêPositive Rate:      12.0700%\n",
      "False‚ÄêNegative Rate:      12.8925%\n",
      "Avg Query Time:           0.000148 s\n",
      "Throughput:               6,738 queries/s\n",
      "\n",
      "=== RandomForestBloomFilter ===\n",
      "Memory Usage:             44,123,000 bytes\n",
      "False‚ÄêPositive Rate:      0.0000%\n",
      "False‚ÄêNegative Rate:      0.0000%\n",
      "Avg Query Time:           0.003678 s\n",
      "Throughput:               272 queries/s\n",
      "\n",
      "=== LogisticRegressionBloomFilter ===\n",
      "Memory Usage:             56 bytes\n",
      "False‚ÄêPositive Rate:      16.0550%\n",
      "False‚ÄêNegative Rate:      0.0000%\n",
      "Avg Query Time:           0.000148 s\n",
      "Throughput:               6,757 queries/s\n",
      "\n",
      "=== SandwichBloomFilter ===\n",
      "Memory Usage:             1,076,280 bytes\n",
      "False‚ÄêPositive Rate:      2.4675%\n",
      "Avg Query Time:           0.000094 s\n",
      "Throughput:               10,652 queries/s\n",
      "\n",
      "=== SandwichBloomFilter ===\n",
      "Memory Usage:             45,195,056 bytes\n",
      "False‚ÄêPositive Rate:      0.0000%\n",
      "Avg Query Time:           0.003469 s\n",
      "Throughput:               288 queries/s\n",
      "\n",
      "=== SandwichBloomFilter ===\n",
      "Memory Usage:             1,072,112 bytes\n",
      "False‚ÄêPositive Rate:      3.2600%\n",
      "Avg Query Time:           0.000084 s\n",
      "Throughput:               11,940 queries/s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filter</th>\n",
       "      <th>Mem (bytes)</th>\n",
       "      <th>FP Rate</th>\n",
       "      <th>FN Rate</th>\n",
       "      <th>Avg Time (s)</th>\n",
       "      <th>Throughput (q/s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Standard</td>\n",
       "      <td>3067328</td>\n",
       "      <td>0.009625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>142569.930768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Counting</td>\n",
       "      <td>3067328</td>\n",
       "      <td>0.009625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>143613.743325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NeuralNet</td>\n",
       "      <td>4224</td>\n",
       "      <td>0.120700</td>\n",
       "      <td>0.128925</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>6738.310515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>44123000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003678</td>\n",
       "      <td>271.915739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegr</td>\n",
       "      <td>56</td>\n",
       "      <td>0.160550</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>6757.327349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sandwich-NeuralNet</td>\n",
       "      <td>1076280</td>\n",
       "      <td>0.024675</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>10652.463734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sandwich-RandomForest</td>\n",
       "      <td>45195056</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003469</td>\n",
       "      <td>288.229624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sandwich-LogisticRegr</td>\n",
       "      <td>1072112</td>\n",
       "      <td>0.032600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>11939.564676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Filter  Mem (bytes)   FP Rate   FN Rate  Avg Time (s)  \\\n",
       "0               Standard      3067328  0.009625       NaN      0.000007   \n",
       "1               Counting      3067328  0.009625       NaN      0.000007   \n",
       "2              NeuralNet         4224  0.120700  0.128925      0.000148   \n",
       "3           RandomForest     44123000  0.000000  0.000000      0.003678   \n",
       "4           LogisticRegr           56  0.160550  0.000000      0.000148   \n",
       "5     Sandwich-NeuralNet      1076280  0.024675       NaN      0.000094   \n",
       "6  Sandwich-RandomForest     45195056  0.000000       NaN      0.003469   \n",
       "7  Sandwich-LogisticRegr      1072112  0.032600       NaN      0.000084   \n",
       "\n",
       "   Throughput (q/s)  \n",
       "0     142569.930768  \n",
       "1     143613.743325  \n",
       "2       6738.310515  \n",
       "3        271.915739  \n",
       "4       6757.327349  \n",
       "5      10652.463734  \n",
       "6        288.229624  \n",
       "7      11939.564676  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# üìè IP Address Dataset\n",
    "print(\"\\U0001f4cf IP Address Dataset Bloom Filter Evaluation\\n\")\n",
    "with open(\"../datasets/ip_addresses/ip_address_positives.txt\") as f:\n",
    "    positives = f.read().splitlines()\n",
    "with open(\"../datasets/ip_addresses/ip_addresses_negatives.txt\") as f:\n",
    "    negatives = f.read().splitlines()\n",
    "\n",
    "filters_ip = [\n",
    "    (\"Standard\", StandardBloomFilter(len(positives), 0.01)),\n",
    "    (\"Counting\", CountingBloomFilter(len(positives), 0.01)),\n",
    "] + [(name, bf) for name, bf in ml_filters] + [\n",
    "    (f\"Sandwich-{name}\", SandwichBloomFilter(bf, positives, negatives, 0.20))\n",
    "    for name, bf in ml_filters\n",
    "]\n",
    "\n",
    "results_ip = []\n",
    "for name, bf in filters_ip:\n",
    "    m = evaluate(bf, positives, negatives)\n",
    "    results_ip.append({\n",
    "        \"Filter\":            name,\n",
    "        \"Mem (bytes)\":       m[\"memory_bytes\"],\n",
    "        \"FP Rate\":           m[\"fpr\"],\n",
    "        \"FN Rate\":           m[\"fnr\"],\n",
    "        \"Avg Time (s)\":      m[\"avg_time\"],\n",
    "        \"Throughput (q/s)\":  m[\"throughput\"],\n",
    "    })\n",
    "\n",
    "df_ip = pd.DataFrame(results_ip)\n",
    "display(df_ip)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìû Phone Number Dataset Bloom Filter Evaluation\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/milesbramwit/cs6386/finalProject/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== StandardBloomFilter ===\n",
      "Memory Usage:             62,528 bytes\n",
      "False‚ÄêPositive Rate:      1.5000%\n",
      "Avg Query Time:           0.000002 s\n",
      "Throughput:               439,516 queries/s\n",
      "\n",
      "=== CountingBloomFilter ===\n",
      "Memory Usage:             62,528 bytes\n",
      "False‚ÄêPositive Rate:      1.5000%\n",
      "Avg Query Time:           0.000002 s\n",
      "Throughput:               433,654 queries/s\n",
      "\n",
      "=== NeuralNetworkBloomFilter ===\n",
      "Memory Usage:             4,224 bytes\n",
      "False‚ÄêPositive Rate:      37.4000%\n",
      "False‚ÄêNegative Rate:      31.9410%\n",
      "Avg Query Time:           0.000083 s\n",
      "Throughput:               12,099 queries/s\n",
      "\n",
      "=== RandomForestBloomFilter ===\n",
      "Memory Usage:             4,042,712 bytes\n",
      "False‚ÄêPositive Rate:      0.0000%\n",
      "False‚ÄêNegative Rate:      0.0000%\n",
      "Avg Query Time:           0.003559 s\n",
      "Throughput:               281 queries/s\n",
      "\n",
      "=== LogisticRegressionBloomFilter ===\n",
      "Memory Usage:             56 bytes\n",
      "False‚ÄêPositive Rate:      26.4000%\n",
      "False‚ÄêNegative Rate:      0.0000%\n",
      "Avg Query Time:           0.000068 s\n",
      "Throughput:               14,666 queries/s\n",
      "\n",
      "=== SandwichBloomFilter ===\n",
      "Memory Usage:             26,144 bytes\n",
      "False‚ÄêPositive Rate:      7.2000%\n",
      "Avg Query Time:           0.000081 s\n",
      "Throughput:               12,285 queries/s\n",
      "\n",
      "=== SandwichBloomFilter ===\n",
      "Memory Usage:             4,064,632 bytes\n",
      "False‚ÄêPositive Rate:      0.0000%\n",
      "Avg Query Time:           0.003690 s\n",
      "Throughput:               271 queries/s\n",
      "\n",
      "=== SandwichBloomFilter ===\n",
      "Memory Usage:             21,976 bytes\n",
      "False‚ÄêPositive Rate:      5.7000%\n",
      "Avg Query Time:           0.000068 s\n",
      "Throughput:               14,744 queries/s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filter</th>\n",
       "      <th>Mem (bytes)</th>\n",
       "      <th>FP Rate</th>\n",
       "      <th>FN Rate</th>\n",
       "      <th>Avg Time (s)</th>\n",
       "      <th>Throughput (q/s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Standard</td>\n",
       "      <td>62528</td>\n",
       "      <td>0.015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>439516.294666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Counting</td>\n",
       "      <td>62528</td>\n",
       "      <td>0.015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>433654.259719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NeuralNet</td>\n",
       "      <td>4224</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.31941</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>12098.593215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>4042712</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.003559</td>\n",
       "      <td>280.987910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegr</td>\n",
       "      <td>56</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>14666.167806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sandwich-NeuralNet</td>\n",
       "      <td>26144</td>\n",
       "      <td>0.072</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>12285.132669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sandwich-RandomForest</td>\n",
       "      <td>4064632</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003690</td>\n",
       "      <td>271.011899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sandwich-LogisticRegr</td>\n",
       "      <td>21976</td>\n",
       "      <td>0.057</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>14744.016170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Filter  Mem (bytes)  FP Rate  FN Rate  Avg Time (s)  \\\n",
       "0               Standard        62528    0.015      NaN      0.000002   \n",
       "1               Counting        62528    0.015      NaN      0.000002   \n",
       "2              NeuralNet         4224    0.374  0.31941      0.000083   \n",
       "3           RandomForest      4042712    0.000  0.00000      0.003559   \n",
       "4           LogisticRegr           56    0.264  0.00000      0.000068   \n",
       "5     Sandwich-NeuralNet        26144    0.072      NaN      0.000081   \n",
       "6  Sandwich-RandomForest      4064632    0.000      NaN      0.003690   \n",
       "7  Sandwich-LogisticRegr        21976    0.057      NaN      0.000068   \n",
       "\n",
       "   Throughput (q/s)  \n",
       "0     439516.294666  \n",
       "1     433654.259719  \n",
       "2      12098.593215  \n",
       "3        280.987910  \n",
       "4      14666.167806  \n",
       "5      12285.132669  \n",
       "6        271.011899  \n",
       "7      14744.016170  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# üìû Phone Number Dataset\n",
    "print(\"\\U0001f4de Phone Number Dataset Bloom Filter Evaluation\\n\")\n",
    "with open(\"../datasets/phone_numbers/phone_numbers_positives.txt\") as f:\n",
    "    positives = f.read().splitlines()\n",
    "with open(\"../datasets/phone_numbers/phone_numbers_negatives.txt\") as f:\n",
    "    negatives = f.read().splitlines()\n",
    "\n",
    "filters_phone = [\n",
    "    (\"Standard\", StandardBloomFilter(len(positives), 0.01)),\n",
    "    (\"Counting\", CountingBloomFilter(len(positives), 0.01)),\n",
    "] + [(name, bf) for name, bf in ml_filters] + [\n",
    "    (f\"Sandwich-{name}\", SandwichBloomFilter(bf, positives, negatives, 0.20))\n",
    "    for name, bf in ml_filters\n",
    "]\n",
    "\n",
    "results_phone = []\n",
    "for name, bf in filters_phone:\n",
    "    m = evaluate(bf, positives, negatives)\n",
    "    results_phone.append({\n",
    "        \"Filter\":            name,\n",
    "        \"Mem (bytes)\":       m[\"memory_bytes\"],\n",
    "        \"FP Rate\":           m[\"fpr\"],\n",
    "        \"FN Rate\":           m[\"fnr\"],\n",
    "        \"Avg Time (s)\":      m[\"avg_time\"],\n",
    "        \"Throughput (q/s)\":  m[\"throughput\"],\n",
    "    })\n",
    "\n",
    "df_phone = pd.DataFrame(results_phone)\n",
    "display(df_phone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìß Email Dataset Bloom Filter Evaluation\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/milesbramwit/cs6386/finalProject/venv/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/Users/milesbramwit/cs6386/finalProject/venv/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== StandardBloomFilter ===\n",
      "Memory Usage:             52,712 bytes\n",
      "False‚ÄêPositive Rate:      1.6012%\n",
      "Avg Query Time:           0.000002 s\n",
      "Throughput:               445,017 queries/s\n",
      "\n",
      "=== CountingBloomFilter ===\n",
      "Memory Usage:             52,712 bytes\n",
      "False‚ÄêPositive Rate:      1.6012%\n",
      "Avg Query Time:           0.000003 s\n",
      "Throughput:               383,840 queries/s\n",
      "\n",
      "=== NeuralNetworkBloomFilter ===\n",
      "Memory Usage:             4,224 bytes\n",
      "False‚ÄêPositive Rate:      5.9680%\n",
      "False‚ÄêNegative Rate:      11.5160%\n",
      "Avg Query Time:           0.000083 s\n",
      "Throughput:               11,990 queries/s\n",
      "\n",
      "=== RandomForestBloomFilter ===\n",
      "Memory Usage:             892,952 bytes\n",
      "False‚ÄêPositive Rate:      0.0000%\n",
      "False‚ÄêNegative Rate:      0.0000%\n",
      "Avg Query Time:           0.003516 s\n",
      "Throughput:               284 queries/s\n",
      "\n",
      "=== LogisticRegressionBloomFilter ===\n",
      "Memory Usage:             56 bytes\n",
      "False‚ÄêPositive Rate:      5.8224%\n",
      "False‚ÄêNegative Rate:      0.0000%\n",
      "Avg Query Time:           0.000067 s\n",
      "Throughput:               14,938 queries/s\n",
      "\n",
      "=== SandwichBloomFilter ===\n",
      "Memory Usage:             22,712 bytes\n",
      "False‚ÄêPositive Rate:      0.7278%\n",
      "Avg Query Time:           0.000081 s\n",
      "Throughput:               12,343 queries/s\n",
      "\n",
      "=== SandwichBloomFilter ===\n",
      "Memory Usage:             911,440 bytes\n",
      "False‚ÄêPositive Rate:      0.0000%\n",
      "Avg Query Time:           0.003499 s\n",
      "Throughput:               286 queries/s\n",
      "\n",
      "=== SandwichBloomFilter ===\n",
      "Memory Usage:             18,544 bytes\n",
      "False‚ÄêPositive Rate:      1.4556%\n",
      "Avg Query Time:           0.000066 s\n",
      "Throughput:               15,067 queries/s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filter</th>\n",
       "      <th>Mem (bytes)</th>\n",
       "      <th>FP Rate</th>\n",
       "      <th>FN Rate</th>\n",
       "      <th>Avg Time (s)</th>\n",
       "      <th>Throughput (q/s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Standard</td>\n",
       "      <td>52712</td>\n",
       "      <td>0.016012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>445017.273822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Counting</td>\n",
       "      <td>52712</td>\n",
       "      <td>0.016012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>383839.995737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NeuralNet</td>\n",
       "      <td>4224</td>\n",
       "      <td>0.059680</td>\n",
       "      <td>0.11516</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>11990.008688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>892952</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.003516</td>\n",
       "      <td>284.374916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegr</td>\n",
       "      <td>56</td>\n",
       "      <td>0.058224</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>14938.265505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sandwich-NeuralNet</td>\n",
       "      <td>22712</td>\n",
       "      <td>0.007278</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>12342.529118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sandwich-RandomForest</td>\n",
       "      <td>911440</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003499</td>\n",
       "      <td>285.819258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sandwich-LogisticRegr</td>\n",
       "      <td>18544</td>\n",
       "      <td>0.014556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>15066.676678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Filter  Mem (bytes)   FP Rate  FN Rate  Avg Time (s)  \\\n",
       "0               Standard        52712  0.016012      NaN      0.000002   \n",
       "1               Counting        52712  0.016012      NaN      0.000003   \n",
       "2              NeuralNet         4224  0.059680  0.11516      0.000083   \n",
       "3           RandomForest       892952  0.000000  0.00000      0.003516   \n",
       "4           LogisticRegr           56  0.058224  0.00000      0.000067   \n",
       "5     Sandwich-NeuralNet        22712  0.007278      NaN      0.000081   \n",
       "6  Sandwich-RandomForest       911440  0.000000      NaN      0.003499   \n",
       "7  Sandwich-LogisticRegr        18544  0.014556      NaN      0.000066   \n",
       "\n",
       "   Throughput (q/s)  \n",
       "0     445017.273822  \n",
       "1     383839.995737  \n",
       "2      11990.008688  \n",
       "3        284.374916  \n",
       "4      14938.265505  \n",
       "5      12342.529118  \n",
       "6        285.819258  \n",
       "7      15066.676678  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# üìß Email Dataset\n",
    "print(\"\\U0001f4e7 Email Dataset Bloom Filter Evaluation\\n\")\n",
    "with open(\"../datasets/emails/spam_email_positives.txt\") as f:\n",
    "    positives = f.read().splitlines()\n",
    "with open(\"../datasets/emails/spam_email_negatives.txt\") as f:\n",
    "    negatives = f.read().splitlines()\n",
    "\n",
    "filters_email = [\n",
    "    (\"Standard\", StandardBloomFilter(len(positives), 0.01)),\n",
    "    (\"Counting\", CountingBloomFilter(len(positives), 0.01)),\n",
    "] + [(name, bf) for name, bf in ml_filters] + [\n",
    "    (f\"Sandwich-{name}\", SandwichBloomFilter(bf, positives, negatives, 0.20))\n",
    "    for name, bf in ml_filters\n",
    "]\n",
    "\n",
    "results_email = []\n",
    "for name, bf in filters_email:\n",
    "    m = evaluate(bf, positives, negatives)\n",
    "    results_email.append({\n",
    "        \"Filter\":            name,\n",
    "        \"Mem (bytes)\":       m[\"memory_bytes\"],\n",
    "        \"FP Rate\":           m[\"fpr\"],\n",
    "        \"FN Rate\":           m[\"fnr\"],\n",
    "        \"Avg Time (s)\":      m[\"avg_time\"],\n",
    "        \"Throughput (q/s)\":  m[\"throughput\"],\n",
    "    })\n",
    "\n",
    "df_email = pd.DataFrame(results_email)\n",
    "display(df_email)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
